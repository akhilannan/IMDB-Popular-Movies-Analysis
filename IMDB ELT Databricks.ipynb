{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "64e18d35-fc05-4e2e-8960-c7b8da33db54",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#Install Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "598dec03-4059-4ecb-b327-541a5f844627",
     "showTitle": false,
     "title": ""
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "!pip install lxml beautifulsoup4 -q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7574876f-303c-4087-b080-2b8032111aa7",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#Initialize URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c496c85b-7346-422b-ba19-09ebcf23916a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "DATASET_URL = \"https://datasets.imdbws.com/\"\n",
    "BOXOFFICE_URL = \"https://www.boxofficemojo.com\"\n",
    "LANGUAGE_URL = \"https://en.wikipedia.org/wiki/List_of_ISO_639-1_codes\"\n",
    "IMDB_URL = \"https://www.imdb.com/\"\n",
    "CHART_URL = f\"{IMDB_URL}chart/\"\n",
    "INDIA_URL = f\"{IMDB_URL}india/\"\n",
    "IMDB_SEARCH_URL = f\"{IMDB_URL}search/title/\"\n",
    "TOP_1000_URL = f\"{IMDB_SEARCH_URL}?groups=top_1000\"\n",
    "LANG_URL = f\"{IMDB_SEARCH_URL}?primary_language\"\n",
    "BOXOFFICE_CHART = f\"{BOXOFFICE_URL}/chart/ww_top_lifetime_gross/?area=XWW&offset=\"\n",
    "BOXOFFICE_YEAR = f\"{BOXOFFICE_URL}/year/world/\"\n",
    "HEADERS = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36 Edg/121.0.0.0',\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6d609d81-911f-41b0-b605-c2d0b1a0e8cf",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#Initialize variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2113e7a7-93b1-4c41-aa88-314f61451fa5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "basePath = \"/user/IMDB/\"\n",
    "rawPath = f\"{basePath}raw/\"\n",
    "silverPath = f\"{basePath}silver/\"\n",
    "goldPath = f\"{basePath}gold/\"\n",
    "topTableName = \"t_imdb_top\"\n",
    "boTableName = \"t_bo\"\n",
    "goldTableName = \"t_imdb\"\n",
    "goldTablePath = goldPath + goldTableName\n",
    "file_list = ['name.basics.tsv.gz', 'title.basics.tsv.gz', 'title.crew.tsv.gz', 'title.principals.tsv.gz', 'title.ratings.tsv.gz']\n",
    "RawFolderList= [file[:-7].replace(\"-co\",\"\") for file in file_list]\n",
    "SilverTableList = [\"t_\"+folderName.replace(\".\",\"_\").replace(\"-co\",\"\") for folderName in RawFolderList]\n",
    "FullTableList = SilverTableList + [goldTableName] + [topTableName] + [boTableName]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "faed06fb-3459-469b-bb59-a3483d532139",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Import Required Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b60760ce-7b50-4bfc-838d-dc8c160a4f95",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql import types as T\n",
    "from pyspark.sql.window import Window\n",
    "import pyspark.pandas as ps\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import date\n",
    "from urllib.request import urlretrieve\n",
    "import re\n",
    "import concurrent.futures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "07f77317-83f7-43b9-b681-eda92c09a91b",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#Drop all tables/folders if exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a4f8145b-8075-456c-be14-18cae1b835a3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.fs.rm(f\"dbfs:{basePath}\", recurse = True)\n",
    "for tbl in FullTableList:\n",
    "  spark.sql(f\"DROP TABLE IF EXISTS {tbl}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "377b0eaf-709a-4008-80d8-eecc65087e55",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Create Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b972bba1-d3b4-4aae-a1d8-4496c7cc8de8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.sql(f\"CREATE SCHEMA IF NOT EXISTS silver location '{silverPath}'\")\n",
    "spark.sql(f\"CREATE SCHEMA IF NOT EXISTS gold location '{goldPath}'\")\n",
    "# for file_info in dbutils.fs.ls(silverPath) + dbutils.fs.ls(goldPath):\n",
    "#   table_path = file_info.path\n",
    "#   table_schema = table_path.split('/')[-3]\n",
    "#   table_name = table_path.split('/')[-2]\n",
    "#   spark.sql(f\"CREATE TABLE IF NOT EXISTS {table_schema}.{table_name} location '{table_path}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "78c3903b-d52f-4633-8cd4-8557e86fd5dc",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Extract Language Codes and names from Wiki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8d8f0407-09d5-43a3-9804-1a82daf58b37",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "lang_df = ps.read_html(LANGUAGE_URL)[0][[\"ISO language name\",\"Set 1\"]]\n",
    "lang_df.columns = ['lang_name','lang_code']\n",
    "lang_df = lang_df.to_spark()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "95933d0d-526c-402f-9f7e-1e491c3abec1",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Function to Scrape Movie Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f0b1461d-125e-496b-9904-6fd2a3323425",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def scrape_movie_data(url):\n",
    "    \"\"\"\n",
    "    Scrapes movie data from the given URL and returns a movie_dict.\n",
    "\n",
    "    Args:\n",
    "        url (str): The URL to scrape.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing movie details.\n",
    "    \"\"\"\n",
    "\n",
    "    # Send an HTTP request to the provided URL\n",
    "    response = requests.get(url, headers=HEADERS)\n",
    "\n",
    "    # Parse the HTML content using BeautifulSoup\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "    # Determine the type of URL\n",
    "    is_box_office_url = BOXOFFICE_URL in url\n",
    "    is_search_url = IMDB_SEARCH_URL in url\n",
    "    is_india_url = INDIA_URL in url\n",
    "    is_yearly_box_office = BOXOFFICE_YEAR in url\n",
    "\n",
    "    # Define the class value based on the URL type\n",
    "    class_value = 'ipc-metadata-list-item__icon-link' if is_india_url else 'ipc-title-link-wrapper'\n",
    "\n",
    "    # Extract movie entries from the HTML content\n",
    "    movie_entries = soup.find_all('table')[0].find_all(\"tr\") if is_box_office_url else soup.find_all('a', class_=class_value, href=True)\n",
    "\n",
    "    # Initialize an empty list to store movie data\n",
    "    movie_data = []\n",
    "\n",
    "    # Iterate through each movie entry\n",
    "    for entry in movie_entries:\n",
    "        # Initialize a dictionary to store movie details\n",
    "        movie_dict = {\n",
    "            \"tconst\": None,\n",
    "            \"rnk\": None,\n",
    "            \"type\": None,\n",
    "            \"rating\": -0.1,\n",
    "            \"votes\": -1,\n",
    "            \"movie_name\": None,\n",
    "            \"movie_year\": None,\n",
    "            \"box_office\": -1\n",
    "        }\n",
    "\n",
    "        if is_box_office_url:\n",
    "            # Extract relevant data from box office URL\n",
    "            row_cols = entry.find_all('td')\n",
    "            if row_cols:\n",
    "                movie_dict['box_office'] = int(row_cols[2].text.replace(\"$\", \"\").replace(\",\", \"\"))\n",
    "                if is_yearly_box_office:\n",
    "                    movie_dict['movie_name'] = row_cols[1].text\n",
    "                    movie_dict['movie_year'] = int(url.split('/')[-1])\n",
    "                else:\n",
    "                    movie_dict['type'] = url.split('/')[-2]\n",
    "                    movie_dict['rnk'] = int(row_cols[0].text.replace(\",\", \"\"))\n",
    "                    movie_dict['tconst'] = re.search(r\"(tt\\d+)\", row_cols[1].find(\"a\")['href']).group(1)\n",
    "        else:\n",
    "            # Extract relevant data from other types of URLs\n",
    "            link = entry.attrs.get('href')\n",
    "            if link and link.startswith('/title/tt'):\n",
    "                movie_dict['tconst'] = re.search(r\"(tt\\d+)\", link).group(1)\n",
    "                movie_dict['movie_name'] = entry.attrs.get('aria-label') if is_india_url else entry.find('h3', class_='ipc-title__text').text.strip()\n",
    "                movie_dict['rnk'] = int(re.search(r\"^(\\d+)\\.\", movie_dict['movie_name']).group(1))\n",
    "                movie_dict['type'] = url.split('/')[-1] if is_search_url else url.split('/')[-2]\n",
    "\n",
    "        # Append the movie details to the list\n",
    "        movie_data.append(movie_dict)\n",
    "\n",
    "    # Return the list of movie data\n",
    "    return movie_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f76d459b-3c0c-402f-aed7-e8c995e4ad83",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Create Spark UDF for Web Scrapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4e20872a-ac28-4e8a-b3b3-895513f301e7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "scrape_movie_data_udf = F.udf(scrape_movie_data, T.ArrayType(T.StructType([\n",
    "    T.StructField(\"tconst\", T.StringType()),\n",
    "    T.StructField(\"rnk\", T.IntegerType()),\n",
    "    T.StructField(\"type\", T.StringType()),\n",
    "    T.StructField(\"rating\", T.DecimalType(3,1)),\n",
    "    T.StructField(\"votes\", T.IntegerType()),\n",
    "    T.StructField(\"movie_name\", T.StringType()),\n",
    "    T.StructField(\"movie_year\", T.IntegerType()),\n",
    "    T.StructField(\"box_office\", T.IntegerType())\n",
    "])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c40ca54f-129d-4815-9516-c5a179136289",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#Extract all Top Rated Movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bf1b1133-230c-4d2d-b0b8-105c95ea43e4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Define the list of URLs to scrape\n",
    "url_list = [\n",
    "    f\"{CHART_URL}{suffix}\" for suffix in [\"toptv/\", \"top/\"]\n",
    "] + [\n",
    "    f\"{INDIA_URL}top-rated-{language}-movies/\" for language in [\"indian\", \"malayalam\", \"tamil\", \"telugu\"]\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d789b3d9-3c6d-46eb-84b0-cad88ec1b37c",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#Extract Top 1000 Movies + Popular Language-wise Movies list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2dafd994-4d21-409e-bcf2-7bd5bc4f2162",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Define the additional URLs to append\n",
    "top_search_urls = [TOP_1000_URL, f\"{IMDB_SEARCH_URL}?release_date=,9999-12-31\"] + [f\"{LANG_URL}={language}\" for language in [\"ml\", \"ta\", \"hi\", \"te\", \"kn\"]]\n",
    "sort_syntax = [\"moviemeter,asc\",\"num_votes,desc\"]\n",
    "rng = range(1,1000,50) \n",
    "\n",
    "# Append the additional URLs to the url_list using list comprehension\n",
    "url_list += [\n",
    "    f'{top_url}&sort={sort}&start={n}'\n",
    "    for top_url in top_search_urls\n",
    "    for sort in sort_syntax\n",
    "    if not (('top_1000' in top_url or 'release_date' in top_url) and 'desc' in sort)\n",
    "    for n in rng\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9b43aa16-b1e7-4e7b-8f24-9d639084f6b3",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Extract All Time Boxoffice Details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "980f223a-aa2e-4300-abe6-1c95bffc71f2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "rng = range(0,1000,200)\n",
    "url_list += [\n",
    "  BOXOFFICE_CHART + str(n)\n",
    "  for n in rng\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f62db914-b2f6-46fa-b914-143d16766326",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Create IMDB Top table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fa1bd98e-4995-43ec-923b-05e3c12b11e7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Create a DataFrame with a single column \"url\"\n",
    "imdb_df = spark.createDataFrame([(url,) for url in url_list], [\"url\"])\n",
    "\n",
    "# Add a new column \"movie_data\" by applying the UDF\n",
    "imdb_df = (\n",
    "  imdb_df\n",
    "  .withColumn(\"movie_data\", F.explode(scrape_movie_data_udf(\"url\")))\n",
    "  .select(\"movie_data.*\")\n",
    "  )\n",
    "\n",
    "# Store patterns to variables\n",
    "primary_language_pattern = \"%primary_language%,%\"\n",
    "\n",
    "# Filter and extract language code\n",
    "imdb_df = (\n",
    "    imdb_df\n",
    "    .filter(F.col(\"tconst\").isNotNull())\n",
    "    .withColumn(\"lang_code\", F.when(F.col(\"type\").like(primary_language_pattern), F.regexp_extract(F.col(\"type\"), r\"primary_language=([a-z]+)\", 1)))\n",
    ")\n",
    "\n",
    "# Join with language DataFrame\n",
    "imdb_df = imdb_df.join(lang_df, \"lang_code\", 'leftouter')\n",
    "\n",
    "# Select columns with conditions\n",
    "select_exprs = [\n",
    "    \"tconst\",\n",
    "    \"lang_name\",\n",
    "    F.col(\"rnk\"),\n",
    "    F.col(\"type\").alias(\"url\")\n",
    "]\n",
    "\n",
    "# Define a dictionary for conditional columns\n",
    "conditional_columns = {\n",
    "    \"rating\": F.col(\"rating\") >= 0,\n",
    "    \"votes\": F.col(\"votes\") >= 0,\n",
    "    \"box_office\": F.col(\"box_office\") >= 0,\n",
    "    \"is_in_top_250\": F.col(\"type\").isin(['toptv','top','top-rated-indian-movies','top-rated-malayalam-movies','top-rated-tamil-movies','top-rated-telugu-movies']),\n",
    "    \"is_in_top_1000\": F.col(\"type\").like(\"%top_1000%\"),\n",
    "    \"is_popular\": F.col(\"type\").like(\"%release_date%moviemeter%\"),\n",
    "    \"is_primary_lang\": F.col(\"type\").like(primary_language_pattern),\n",
    "    \"is_asc\": F.col(\"type\").like(\"%,asc&%\"),\n",
    "    \"is_desc\": F.col(\"type\").like( \"%,desc&%\")\n",
    "}\n",
    "\n",
    "# Add conditional columns\n",
    "for col_name, condition in conditional_columns.items():\n",
    "  if col_name.startswith(\"is_\"):\n",
    "    select_exprs.append(F.when(condition, F.lit('Y')).otherwise(F.lit('N')).alias(col_name))\n",
    "  else:\n",
    "    select_exprs.append(F.when(condition, F.col(col_name)).alias(col_name))\n",
    "\n",
    "# Select the final columns\n",
    "imdb_df = imdb_df.select(*select_exprs)\n",
    "\n",
    "# Write to table\n",
    "(\n",
    "  imdb_df\n",
    "  .write\n",
    "  .format(\"delta\")\n",
    "  .mode(\"overwrite\")\n",
    "  .option(\"overwriteSchema\",\"true\")\n",
    "  .saveAsTable(f\"silver.{topTableName}\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6ab14ab5-468d-4fae-bbd4-f58d5d8fe900",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Extract Yearly Box Office Details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0993ef77-9f06-40e8-a0ff-5d3367be189c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "current_year = date.today().year\n",
    "rng = range(1977,current_year+1,1)\n",
    "yearly_box_office_url_list =  [\n",
    "  BOXOFFICE_YEAR + str(n)\n",
    "  for n in rng\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c3321b90-af9e-4b9c-81d5-c7a18e2b58c9",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Create Dataframe and build t_bo table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "981413f0-73d0-46ae-bebb-d2da6581e5b0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "bo_df = spark.createDataFrame([(url,) for url in yearly_box_office_url_list], [\"url\"])\n",
    "\n",
    "bo_df = (\n",
    "  bo_df\n",
    "  .withColumn(\"movie_data\", F.explode(scrape_movie_data_udf(\"url\")))\n",
    "  .filter(F.col(\"movie_data.movie_name\").isNotNull())\n",
    "  .select(\"movie_data.movie_name\",\n",
    "          \"movie_data.movie_year\",\n",
    "          \"movie_data.box_office\")\n",
    "  )\n",
    "\n",
    "(\n",
    "  bo_df\n",
    " .write\n",
    " .format(\"delta\")\n",
    " .mode(\"overwrite\")\n",
    " .option(\"overwriteSchema\",\"true\")\n",
    " .saveAsTable(f\"silver.{boTableName}\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8891f54b-aa52-4e45-81be-e0b83e987658",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#Download the datasets to driver and move to Raw storage folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7f1c1348-351d-4365-a958-deceee057047",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "for file in file_list:\n",
    "  tablename = file[:-7].replace(\"-co\",\"\")\n",
    "  extn = file[-3:]\n",
    "  BaseURL = DATASET_URL + file\n",
    "  DriverPath = f\"file:/databricks/driver/{file}\"\n",
    "  dbfsPath = f\"dbfs:{rawPath}{tablename}/{file}\"\n",
    "  urlretrieve(BaseURL,file)\n",
    "  dbutils.fs.mv(DriverPath, dbfsPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c1faca06-907d-451a-9b48-eec871d27a13",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#Create Silver Delta tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e28944ce-26ed-46a9-8830-dcf7cc89eead",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Create function for reading from raw and writing to silver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7473c98a-8316-4dfe-975d-b546c48a7990",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def load_table(rawFolderName):\n",
    "  rawFilePath = rawPath + rawFolderName\n",
    "  silverTableName = \"t_\"+rawFolderName.replace(\".\",\"_\")\n",
    "  silverSavePath = silverPath + silverTableName\n",
    "  delim = \"\\t\"\n",
    "  df = (\n",
    "    spark\n",
    "    .read\n",
    "    .format(\"csv\")\n",
    "    .option(\"inferSchema\", \"false\")\n",
    "    .option(\"header\",\"true\")\n",
    "    .option(\"delimiter\",delim)\n",
    "    .load(rawFilePath)\n",
    "  )\n",
    "  colToChange = {'averageRating':'decimal(3,1)', 'numVotes':'int', 'startYear':'int', 'runtimeMinutes':'int'}\n",
    "  dfColToChange= {k:v for (k,v) in colToChange.items() if k in df.columns}\n",
    "  for colName, dataType in dfColToChange.items():\n",
    "    df= df.withColumn(colName, F.expr(f\"try_cast({colName} as {dataType})\"))\n",
    "  (\n",
    "    df\n",
    "    .write\n",
    "    .format(\"delta\")\n",
    "    .mode(\"overwrite\")\n",
    "    .option(\"overwriteSchema\",\"true\")\n",
    "    .saveAsTable(f\"silver.{silverTableName}\")\n",
    "  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4a3a1deb-575b-4907-aa77-16bbfd79e186",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Execute the load_table function for multiple tables in parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c0983541-9994-4b01-b047-bf60f628cd8e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from threading import Thread\n",
    "from queue import Queue\n",
    "\n",
    "q = Queue()\n",
    "\n",
    "worker_count = 5 # Number of tables which will be loaded in parallel\n",
    "\n",
    "def run_tasks(function, q):\n",
    "    while not q.empty():\n",
    "        value = q.get()\n",
    "        function(value)\n",
    "        q.task_done()\n",
    "\n",
    "for rawFolderName in RawFolderList:\n",
    "    q.put(rawFolderName)\n",
    "\n",
    "for i in range(worker_count):\n",
    "    t=Thread(target=run_tasks, args=(load_table, q))\n",
    "    t.daemon = True\n",
    "    t.start()\n",
    "\n",
    "q.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "82ff669b-21ff-427f-a933-b0d4bbf542a3",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#Create Gold Table (PySpark approach)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c4220e83-725b-4111-b089-6c02b46bff4e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Declare Dataframes\n",
    "tbs = spark.table('silver.t_title_basics').alias(\"tbs\")\n",
    "trt = spark.table('silver.t_title_ratings').alias(\"trt\")\n",
    "tnb = spark.table('silver.t_name_basics').alias(\"tnb\")\n",
    "imd = spark.table('silver.t_imdb_top').alias(\"imd\")\n",
    "tps = spark.table('silver.t_title_principals').alias(\"tps\")\n",
    "tcr = spark.table('silver.t_title_crew').alias(\"tcr\")\n",
    "tbo = spark.table('silver.t_bo').alias(\"tbo\")\n",
    "\n",
    "# Get Crew informations\n",
    "tps = (\n",
    "     tps\n",
    "     .filter(F.col(\"category\").isin(['actor', 'actress']))\n",
    "     .select(\"tconst\", \n",
    "             \"category\", \n",
    "             \"nconst\")\n",
    ")\n",
    "tcr = (\n",
    "     tcr\n",
    "     .filter(~F.col(\"directors\").like(\"_N\"))\n",
    "     .select(\"tconst\", \n",
    "             F.lit(\"director\").alias(\"category\"), \n",
    "             F.explode(F.split(F.col(\"directors\"), ',')).alias(\"nconst\"))\n",
    ")\n",
    "tps = tps.union(tcr)\n",
    "\n",
    "# Get Box office informations\n",
    "tbo = (\n",
    "     tbo\n",
    "     .join(tbs,(tbo.movie_name == tbs.primaryTitle) & (tbo.movie_year == tbs.startYear) & (tbs.titleType == F.lit(\"movie\")), 'inner')\n",
    "     .join(trt, trt.tconst == tbs.tconst, 'inner')\n",
    ")\n",
    "tbo = tbo.withColumn(\"rnk\", F.row_number().over(Window\n",
    "                                               .partitionBy(\"tbs.primaryTitle\",\"tbs.startYear\")\n",
    "                                               .orderBy(F.col(\"trt.numvotes\").desc(),\n",
    "                                                        F.col(\"tbo.box_office\").desc())))\n",
    "tbo = (\n",
    "     tbo\n",
    "     .filter(F.col(\"rnk\") == 1)\n",
    "     .select(F.col(\"tbs.tconst\").alias(\"tconst\"), \"tbo.box_office\")\n",
    ")\n",
    "\n",
    "# Final dataframe which is one row per title\n",
    "tbs = tbs.filter(F.col(\"tbs.titletype\").isin(['movie','tvMiniSeries','short','tvSeries','tvShort','tvSpecial']))\n",
    "tbs = (\n",
    "     tbs\n",
    "     .join(trt, trt.tconst == tbs.tconst, 'leftouter')\n",
    "     .join(tps, tps.tconst == tbs.tconst, 'leftouter')\n",
    "     .join(tnb, tnb.nconst == tps.nconst, 'leftouter')\n",
    "     .join(imd, imd.tconst == tbs.tconst, 'leftouter')\n",
    "     .join(tbo, tbo.tconst == tbs.tconst, 'leftouter')\n",
    ")\n",
    "tbs = (\n",
    "     tbs\n",
    "     .groupBy(\"tbs.tconst\")\n",
    "     .agg(F.max(F.regexp_replace(F.initcap(\"tbs.titletype\"), 'Tv', 'TV ')).alias(\"title_type\"),\n",
    "          F.max(\"tbs.primarytitle\").alias(\"primary_title\"),\n",
    "          F.max(\"tbs.originaltitle\").alias(\"original_title\"),\n",
    "          F.max(\"tbs.startyear\").alias(\"yr\"),\n",
    "          F.max(F.when(F.col(\"tbs.isadult\") == 1,\"Y\").otherwise(\"N\")).alias(\"is_adult\"),\n",
    "          F.max(\"tbs.runtimeminutes\").alias(\"runtime_min\"),\n",
    "          F.max(F.when(~F.col(\"tbs.genres\").like(\"_N\"), F.col(\"genres\"))).alias(\"genres\"),\n",
    "          F.coalesce(F.max(\"imd.rating\"), F.max(\"trt.averagerating\")).alias(\"avg_rating\"),\n",
    "          F.coalesce(F.max(\"imd.votes\"), F.max(\"trt.numvotes\")).alias(\"num_votes\"),\n",
    "          F.abs(F.coalesce(F.max(\"imd.box_office\"), F.max(\"tbo.box_office\"))).alias(\"box_office\"),\n",
    "          F.max(F.when(F.col(\"imd.is_in_top_250\") == 'Y', F.col(\"imd.rnk\"))).alias(\"top_250_rnk\"),\n",
    "          F.max(F.when(F.col(\"imd.is_in_top_1000\") == 'Y', F.col(\"imd.rnk\"))).alias(\"top_1000_rnk\"),\n",
    "          F.max(F.when(F.col(\"imd.is_popular\") == 'Y', F.col(\"imd.rnk\"))).alias(\"popularity_rnk\"),\n",
    "          F.max(F.when((F.col(\"imd.is_primary_lang\") == 'Y') & (F.col(\"imd.is_asc\") == 'Y'), F.col(\"rnk\"))).alias(\"language_popularity_rnk\"),\n",
    "          F.max(F.when((F.col(\"imd.is_primary_lang\") == 'Y') & (F.col(\"imd.is_desc\") == 'Y'), F.col(\"rnk\"))).alias(\"language_votes_rnk\"),\n",
    "          F.coalesce(F.max(\"imd.is_in_top_1000\"), F.lit('N')).alias(\"is_top_1000_movies\"),\n",
    "          F.concat_ws('; ', F.collect_set(\"imd.lang_name\")).alias(\"language_lst\"),\n",
    "          F.concat_ws('; ', F.collect_set(F.when(F.col(\"tps.category\") == 'director', F.col(\"tnb.primaryname\")))).alias(\"director_lst\"),\n",
    "          F.concat_ws('; ', F.collect_set(F.when(F.col(\"tps.category\") == 'actor', F.col(\"tnb.primaryname\")))).alias(\"actor_lst\"),\n",
    "          F.concat_ws('; ', F.collect_set(F.when(F.col(\"tps.category\") == 'actress', F.col(\"tnb.primaryname\")))).alias(\"actress_lst\"),\n",
    "          F.lit(F.current_date()).alias(\"last_refresh_date\"))\n",
    ")\n",
    "tbs = (\n",
    "     tbs\n",
    "     .select([\n",
    "              F.when(F.col(c) == \"\", None).otherwise(F.col(c)).alias(c)\n",
    "              if c in [\"language_lst\", \"director_lst\", \"actor_lst\", \"actress_lst\"]\n",
    "              else F.col(c)\n",
    "              for c in tbs.columns\n",
    "              ])\n",
    ")\n",
    "(\n",
    " tbs\n",
    " .write\n",
    " .format(\"delta\")\n",
    " .mode(\"overwrite\")\n",
    " .option(\"overwriteSchema\",\"true\")\n",
    " .saveAsTable(f\"gold.{goldTableName}\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "82f7d241-4a7a-44e1-9318-473139ae296a",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#Create view for Reporting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2d257a09-db94-4dbf-b0bb-bf17f71abc69",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "CREATE OR REPLACE VIEW v_imdb AS\n",
    "select\n",
    "  tconst as `IMDB ID`,\n",
    "  title_type as `Title Type`,\n",
    "  primary_title as `Primary Title`,\n",
    "  original_title as `Original Title`,\n",
    "  yr as `Release Year`,\n",
    "  is_adult as `Is Adult`,\n",
    "  runtime_min as `Runtime in Min`,\n",
    "  genres as `Generes`,\n",
    "  top_250_rnk as `Top 250 Rank`,\n",
    "  row_number() over(\n",
    "    order by\n",
    "      popularity_rnk asc nulls last,\n",
    "      language_popularity_rnk asc nulls last,\n",
    "      top_1000_rnk asc nulls last,\n",
    "      language_votes_rnk asc nulls last,\n",
    "      num_votes desc nulls last\n",
    "  ) as `Popularity Rank`,\n",
    "  is_top_1000_movies as `Is in Top 1000 Movies`,\n",
    "  language_lst as `Languages`,\n",
    "  avg_rating,\n",
    "  num_votes,\n",
    "  box_office,\n",
    "  director_lst as `Directors`,\n",
    "  actor_lst as `Actors`,\n",
    "  actress_lst as `Actresses`,\n",
    "  last_refresh_date as `Last Refresh Date`\n",
    "from\n",
    "  gold.t_imdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "79c86e45-6e7e-40c1-848a-3e2274c9a435",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "select\n",
    "  count(*)\n",
    "from\n",
    "  gold.t_imdb"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 4109608219286031,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 2
   },
   "notebookName": "IMDB ELT (1)",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
